---
title: "Machine learning II"
subtitle: "Predicting the Geographical Origin of Music"
author: "Matthias Kunz, Stefan Beuchert, Adriana Sanchez, Vy Nguyen"
date: "11.01.2022"
bibliography: bibliography.bib
output:
  pdf_document: 
    toc: true
    toc_depth: 2
  html_document: default
  
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# notes
```{r todos, include=TRUE}
print("scatter plot für koordinaten und box plot für varianz in long und lat") # why did we want this? its in the project, but the scatter plot is basically just the map without the cool parts 
print("boxplot für distances für jedes modell -> um diese vergleichen zu können")
print("für finales ergebniss, ein karte, welche ? ist und soll koorinaten anzeigt und mit linien verbindet")
```

# librarys

```{r import_libs, include=TRUE}
#install.packages("installr")
#library("installr")
#install.Rtools()

#install.packages("ggmap")
#install.packages("maptools")
#install.packages("maps")
#install.packages("glmnet")
#install.packages("ISLR")
#TODO the one below necessary?
#install.packages("rgl")
#install.packages("dplyr")

library("glmnet")
library("ggplot2")
library("ggmap")
library("maptools")
library("maps")
library("dplyr")

library(ISLR)
options(rgl.printRglwidget = TRUE)
library(rgl)

library(keras)
library(tensorflow)

```

# Comparison of machine learning algorithms / Introduction / Theory

This report attempts to compare two regression/classification algorithms on its behavior on a specific data set. What should be found out?

Ethnomusicology is the study of music in its social and cultural contexts. Being a highly interdisciplinary field of research, we found interesting trying to apply some machine learning algorithms: ridge regression and neural networks  and compare its results.  

# Data set
Here should be a bit of a short summary of the data set with some key characteristics of the data set.

What is it about? Which variables are included? What type of variables?
What is missing? What about missing values?

The data used in this project is provided by the authors of the paper "Predicting the Geographical Origin of Music"[@Zhou2015 how crated and used this set as basis for this paper. The key information embedded in this data set are attributes of music pieces labeled by there point of origin.

The authors collected 1,142 pieces of music from a personal CD-collection. The target values represented by longitude and latitude are the main country/area of residence of the artists that produced the music. Over all the authors collected music from 73 countries/areas not including western style music, since this category is called to have a global influence and therefor unfitted for predicting a specific country/region. 

The attributes to describe the music pieces are automatically created by a software called MARSYAS[@tzanetakis2007marsyas], a software created to extract audio features from wave files. With MARSYAS the authors could convert every music peace to a set of 116 features called 'chromatic features'. The features are numerical and the authors claim to have normalized them into a gaussian normal distribution.

Selected task is suitable for classification and regression. However we decided that regression is a better approach because in first instance we don't have enough data to be representative to each country and secondly because of the special characteristics of desired output, coordinates.

In order to deal with our spatial output data we'd created a function to scale from our predicted and real values for further model evaluation.

```{r functions, include=TRUE}
distances <- function(predicted, actual_value) {
  dif <- predicted-actual_value
  dif <- dif * (40030/360) # scaling coordinates to km by the factor circumference (km) / 360°
  mse <- sqrt(dif[,1]^2 + dif[,2]^2)
  return(mse)
}
```

```{r import_files, include=TRUE}
data <- read.csv("Data/default_plus_chromatic_features_1059_tracks.txt", header=FALSE)
data <- as.data.frame(data)
colnames(data)[117:118] <- c("Latitude", "Longitude")
```

```{r preprocessing, include=TRUE}
# Maybe some more preprocessing could be done here.
anyNA(data) # testing if there is at least a single NA -> but in this dataset there isn't
# Maybe some more pre-processing could be done here.
anyDuplicated(data) # testing for duplicates -> 0 found

# feature scaling

# separate labels from features
#label_column_names <- c("Longitude", "Latitude")
#data_labels <- data[label_column_names]
#data_features <- subset(data, select = -label_column_names)
# scale features
#data_features_scaled <- as.data.frame(scale(data_features))
# add labels to the now scaled features
#data <- cbind(data_features_scaled, data_labels)


```

# some insights into the data

```{r check_if_standardized, include=TRUE, fig.align='center', out.width='.49\\linewidth', fig.show="hold"}
# check if data is already standardized

# get columns without the target cols ("long" and "lat")
data_without_target_cols <- subset(data, select=-c(Latitude,Longitude))

# for each column in the data get sd and median
sd_per_col <- apply(data_without_target_cols, 2, sd) # the two stands for columns, if we would have used 1 it would calculate the sd of the rows
sd_per_col_df <- data.frame(sd_per_col)

mean_per_col <- apply(data_without_target_cols, 2, mean)
mean_per_col_df <- data.frame(mean_per_col)

sd_and_mean_per_col_df <- merge(sd_per_col_df, mean_per_col_df, by="row.names", all=TRUE)

#par(mar = c(4, 4, .1, .1)) # to make the two plots show side by side and not above each other

boxplot(sd_per_col, data=sd_and_mean_per_col_df, xlab="standard deviation (blue line at 1)", y_lab="value", main="standard deviation of the 116 columns")
abline(h=1, col = "blue", lty=5)

boxplot(mean_per_col, data=sd_and_mean_per_col_df, xlab="mean (blue line at 0)", y_lab="value", main="mean of the 116 columns")
abline(h=0, col = "blue", lty=5)
```


```{r insights_create_worldmap, include=TRUE}
# basic world map with music origins
mapWorld <- borders("world", colour="gray50", fill="white")
mp <- ggplot() + mapWorld

mp + geom_point(data = data, aes(x = Longitude, y = Latitude), color = "red", alpha = 0.5)
```

# Conspicuousness
When looking at the map, it seems like there are way fewer unique data points than expected. The paper states that there are 1,142 pieces from 73 countries/areas, but counting the point on the map just returns 33 data points. The following code investigates this difference.

```{r insights_the_region_conspiracy, include=TRUE}
# investigate why there are fewer points on the map than regions on the map
# data is the full data set

# group data by unique combinations of long and lat and safe in data frame
# and count occurrences of each unique combination
# the unique combinations of long and lat represent regions
occurences_per_region <- data.frame(data %>% count(Longitude, Latitude, sort=TRUE))

nrow(occurences_per_region) # returns 33 -> 33 regions in the data set and not 71 like proposed in the paper -> maybe not all data has been uploaded 

sum(occurences_per_region[, 'n']) # returns 1059 -> therefore there are 1095 tracks in the data set
```

The results suggest that there are actually only 33 unique combinations of latitude and longitude in the data set. Therefore the pieces can only be categorized into 33 different categories. The reason for this discrepancy to the suggested number in the paper (73) might be that some regions have been aggregated prior to uploading the data or some row are missing. The second statement is also supported, by the fact that there are not 1,142 pieces in the data set as described in the paper, but only 1059 pieces. Whatever this (small) difference does not influence the tasked tackled/perused by this report.

```{r insights_draw_worldmap, include=TRUE}
plot(data$Longitude, data$Latitude, xlim=c(-180, 180), ylim=c(-90, 90))
```


```{r insights_3, include=TRUE}
df_lat <- data.frame(value = data$Latitude, dimension = "Latitude")
df_long <- data.frame(value = data$Longitude, dimension = "Longitude")
boxplot_df <- rbind(df_lat, df_long)

boxplot(value~dimension, data=boxplot_df)
```

```{r split_into_test_and_train, include=TRUE}
set.seed(1)
n <-dim(data)[1]
train <- sample(1:n, 0.8*n)
test <- (1:n)[-train]
```



# Method
Short summary about the algorithms. Which are used? What do we do? Classification or Regression?

We treat the problem of predicting the geographical origin of music as a regression problem since we want to predict the spherical coordinates (longitude and latitude).
In Zhou et al. [@Zhou2015] they list two reasons as to why it's preferably not treated as a classification problem: One, the ratio between the large number of countries/areas and the number of examples per country/area is very disproportional and would result in poor classification results. And secondly, with regression we already have a natural error metric: The geographical distance from the true position.

## Baseline - Linear Regression

First, we take a baseline to get a basic understanding on how well our chosen algorithms perform. Therefore, we decided to use a linear regression. First we created a model which includes all variables. The lm() command cannot compute a model for both output variables at the same time. So it creates two separate linear models, one for each output variable:

```{r linear_regression_all_variables, include=TRUE}
model.lm.all <- lm(cbind(Longitude, Latitude)~., data=data[train,])
pred.all <- predict(model.lm.all, newdata=data[test,])
```

To calculate a good meaningful measurement for the goodness of fit for the predictions the distance from the true location is calculated. The distances are calculated as the euclidean distances of the Longitude and Latitude between the predictions and the true location. They are measured in [km]. These will be used for all the comparisons of the algorithms between each other but also with the baseline and also with the literature (we need here another citation to the original paper)

The predictions are on average quite far from the true destination:
```{r linear_regression_all_variables_result, include=TRUE, echo=FALSE}
mean(distances(pred.all, data[test, c("Latitude","Longitude")])) ## final result in km
```

The impact of the variables was analysed. It seemed that not all of them have a significant influence on the models. So a second model was developed, just using the variable which have a significiant influence on the full model, either on the Latitude or on the Longitude. 


```{r linear_regression_significant_variables, include=TRUE}
model.lm.sig <- lm(cbind(Longitude, Latitude)~ V4+V9+V16+V30+V32+V33+V37+V38+V61+V90+V91+V92+V95+V96
                   +V104+V5+V6+V8+V9+V11+V15+V34+V39+V63+V94+V97, 
                   data=data[train,])
pred.sig <- predict(model.lm.sig, newdata=data[test,])
```

The predictions for the smaller models are on average a bit better:
```{r linear_regression_significant_variables_result, include=TRUE, echo=FALSE}
mean(distances(pred.sig, data[test, c("Latitude","Longitude")])) ## final result in km
```

An ANOVA was calculated to check if there is a significant difference between the two models. 
```{r linear_regression_anova, include=TRUE}
anova(model.lm.all, model.lm.sig)
```

The model tells that there is a difference and, as seen before, the smaller model performs better.


```{r linear_regression_boxplot, echo=FALSE}
# TODO:  in GGPLOT2
boxplot(c(distances(pred.sig, data[test, c("Latitude","Longitude")]), distances(pred.all, data[test, c("Latitude","Longitude")]))) 
```

## Algorithm 1 - Ridge Regression

Short introduction of the first algorithm. What does it do? What are the strengths? What are weaknesses? How is it implemented, including major code snippets.

The first algorithm we tried was ridge regression. This algorithm is similar to a linear regression but while the linear regression tries to minimize the difference between the weighted input variables and the output data, the ridge regression adds a regularisation term on the input variables. 

[Here has to be added the formula of the ridge regression]

In fact, this is a possibility to fight over-fitting. If lambda is big the model tends to just take the b0 into account. So the predicted value is the mean of the output variable. If lambda is small, then the model tends to be normal non-regularised model, hence the one from the linear regression. 

The command glmnet is used to perform the ridge regression. Cross-validation is performed to find the optimal lambda values. In general, it would be possible with glmnet to just calculate one single model for both output variables. But unfortunately, this option is not available when doing the cross-validation. So, again two independent cross-validations are done to get two values for lambda, one for each output variable.

```{r ridge_data_preparation, include=TRUE, echo=FALSE}
x <- model.matrix(cbind(Longitude, Latitude)~., data)[,1:116]
y <- data[, c("Latitude","Longitude")]
```

```{r ridge_data_cv, include=TRUE, echo=FALSE}
ridge.mod.1 <- cv.glmnet(x[train,], y[train,1], alpha=0)
plot(ridge.mod.1) # TODO: Here has to be GGPLOT used
bestlam1 <- ridge.mod.1$lambda.min

ridge.mod.2 <- cv.glmnet(x[train,], y[train,2], alpha=0)
plot(ridge.mod.2) # TODO: Here has to be GGPLOT used
bestlam2 <- ridge.mod.2$lambda.min
```
It can be seen that the distributions for lambda are quite similar for both models. Although the MSE for both models differ the optimal lambda is quite similar:

```{r ridge_best_lambda, include=TRUE, echo=FALSE}
bestlam1
bestlam2
```

The model performs better with ridge regression as with the baseline. In this model two lambdas are used.

```{r ridge_data_two_lambdas, include=TRUE, echo=FALSE}
pred1 <- predict(ridge.mod.1, s=bestlam1, newx=x[test,])
pred2 <- predict(ridge.mod.2, s=bestlam2, newx=x[test,])

pred <- cbind(pred1, pred2)
mean(distances(pred, data[test, c("Latitude","Longitude")])) ## final result in km
```

A second result is calculated with just one lambda. This lambda is calculated as the mean of the before calculated values of lambda. The result for the adapted version is just slightly worse than with the model with two independent lambdas:

```{r ridge_data_mean_lambda, include=TRUE, echo=FALSE}
pred1 <- predict(ridge.mod.1, s=(bestlam1+bestlam2)/2, newx=x[test,])
pred2 <- predict(ridge.mod.2, s=(bestlam1+bestlam2)/2, newx=x[test,])


pred <- cbind(pred1, pred2)
mean(distances(pred, data[test, c("Latitude","Longitude")])) ## final result in km
```




```{r Matthias_playground_ridge, include=FALSE}
grid <- 10^seq(10, -2, length=100)
x <- model.matrix(cbind(Longitude, Latitude)~., data)[,1:116]
y <- data[, c("Latitude","Longitude")]
#set.seed(100)


## This is code for the evaluation how lambda for the models differ depending on the output variable (Latitude vs. Longitude)

#outputs <- matrix(nrow=100, ncol=2)
#for (r in 1:100) {
#  out1 <- cv.glmnet(x[train,], y[train,1], alpha=0)
#  #plot(out1)
#  bestlam <- out1$lambda.min
#  outputs[r,1] <- bestlam
#  out2 <- cv.glmnet(x[train,], y[train,2], alpha=0)
#  #plot(out2)
#  bestlam <- out2$lambda.min
#  outputs[r,2] <- bestlam
#}

#xx <- outputs[,1]
#yy <- outputs[,2]
#t.test(xx,yy)
#boxplot(outputs)

# Ridge regression with cross-validation depending on tw separate models
ridge.mod.1 <- cv.glmnet(x[train,], y[train,1], alpha=0)
plot(ridge.mod.1)
bestlam1 <- ridge.mod.1$lambda.min

ridge.mod.2 <- cv.glmnet(x[train,], y[train,2], alpha=0)
plot(ridge.mod.2)
bestlam2 <- ridge.mod.2$lambda.min

# predictions for two separate models
pred1 <- predict(ridge.mod.1, s=bestlam1, newx=x[test,])
pred2 <- predict(ridge.mod.2, s=bestlam2, newx=x[test,])

pred <- cbind(pred1, pred2)
mean(distances(pred, data[test, c("Latitude","Longitude")])) ## final result in km

# predictions for a model using just one lambda (mean)
pred1 <- predict(ridge.mod.1, s=(bestlam1+bestlam2)/2, newx=x[test,])
pred2 <- predict(ridge.mod.2, s=(bestlam1+bestlam2)/2, newx=x[test,])


pred <- cbind(pred1, pred2)
mean(distances(pred, data[test, c("Latitude","Longitude")])) ## final result in km

```


## Algorithm 2 - Artificial Neural Networks (NNs)
Short introduction of the second algorithm. What does it do? What are the strengths? What are weaknesses? How is it implemented, including major code snippets.

For the second algorithm we'll be using Artificial Neural Networks (NNs) as they can be used for regression problems as well. 
To use NNs for our predictions we will, as with all machine learning models, fit the data to the model. This is done by minimizing the loss function, which for NN-regression is the mean of squared errors MSE over the training set.
In the case of fitting a neural network, it is much faster if the data are scaled/normalised first and also gives more appropriate results if the features that are used have different scales and ranges. But this is already the case here.

The NN takes all features from the training data and outputs two values for the Latitude and Longitude, so it is a multi-output regression. In-between Input and Output Layer are a few more layers defined which all use ReLU as activation function. For compiling and fitting the model we again use the Mean Squared Error (MSE) and Adam as the optimizer. We let the model train for 100 epochs with a batch size of 128 and validation split of 0.2.

The results are visualized below.

```{r Vy_playground_NNs, include=TRUE, echo=FALSE}
X_train<-as.matrix(x[train,])
y_train<-as.matrix(y[train,])
X_test<-as.matrix(x[test,])
y_test<-as.matrix(y[test,])

# Initialize a sequential model
model <- keras_model_sequential() 

# Add layers to the model
model %>% 
    layer_dense(units=64, activation = "relu", input_shape = c(116)) %>% 
    #layer_dense(units=32, activation = "relu") %>% 
    layer_dense(units=16, activation = "relu") %>% 
    layer_dense(units=8, activation = "relu") %>% 
    #layer_dense(units=4, activation = "relu") %>% 
    layer_dense(units=2, activation="linear")

# Compile the model
model %>% compile(
     loss = 'mse',
     optimizer = 'adam',
     metrics = list("mean_squared_error", "mean_absolute_error")
 )

model %>% summary()

# Fit the model and store the fitting history in `history` 
history <- model %>% fit(
     X_train, 
     y_train, 
     epochs = 100,
     batch_size = 128, 
     validation_split = 0.2
 )

# Plot the history
plot(history)

# Plot the MSE of the training data 
plot(history$metrics$mean_squared_error, main="Model's Mean Squared Error", xlab = "epoch", ylab="mae", col="blue", type="l")

# Plot the MSE of the validation data
lines(history$metrics$val_mean_squared_error, col="green")

# Add Legend
legend("topright", c("train","val_train"), col=c("blue", "green"), lty=c(1,1))

# MSE of train data
y_preds_train<-model %>% predict(X_train)
mean((y_train - y_preds_train)^2)

# Customized distance metric
mean(distances(y_train, y_preds_train)) 

```

For evaluation we predict the Longitude and Latitude for the same test data as for the other regression cases and use the MSE as well as the custom distance metric. We get the following results:

```{r Vy_playground_NN_distance_metric, include=TRUE, echo=FALSE}
### Test data ###

# Predict the Latitude for the test data
y_pred <- model %>% predict(X_test)

# Evaluate with MSE
mean((y_test - y_pred)^2)

# Evaluate on test data and labels with customized distance metric
mean(distances(y_test, y_pred))                   # 4122.794
```


# Results
Here some tables, summaries or especially graphs should be shown here. Maybe this section should be separated into two to show the algorithms for themselves

We decided on compare a traditional regression method against a more modern architecture like neural network assuming that the last one would perform better overall. First, in our implementation of ridge regression we are fitting two separate models in order to get the two desired output variables. Nevertheless, we know that latitude and longitude are correlated variables, fact that ridge regression doesn't take into account so we expected a bigger error than NN. In the contrary, above implementation of neural network is predicting two variables at once like examples given in paper. 

#

# Discussion
 
Here follows the discussion of the results. What are the major findings? How did the algorithms perform? Which one was better overall? Is it always better or were the findings which were better by the other one?
Which one should be implemented? How could the algorithm be tweaked to perform even better?
Where were the problems during implementation? Where are the limits for the algorithms?
How precise do we predict the cities? How far is the difference in kilometers? The authors of the paper where the dataset comes from have a mean great circle error of 3113km? Are we above or below and by how much?

As we introduced, predicting data points on the Earth using a latitude/longitude representation adds complexity to our problem because of the natural characteristics of coordinates. In first place longitude is discontinuous, meaning that the longitude of two points geographically near might be significantly different and secondly because coordinates are not linear. 

If we compare the two models applied by looking at MSE we know that neural network performs better than ridge regression, as we assumed.However the difference is not big ___ km. Nevertheless, the algorithms presented in In Zhou et al. [@Zhou2015] (KNN and RFR) performs significantly better than ours, achieving an average distance error from 3,100 km to 3,600 km.


# Conclusion
At final some conclusions about the key findings and which algorithm should be used. What was the goal? Were and how were they achieved?
